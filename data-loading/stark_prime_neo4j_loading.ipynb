{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Emfv1O6ygGP"
   },
   "source": [
    "# Load STaRK Prime Into Neo4j\n",
    "\n",
    "Resources\n",
    "- [STaRK GitHub](https://github.com/snap-stanford/stark)\n",
    "- [STaRK Prime Docs](https://stark.stanford.edu/dataset_prime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LURx6A1hL3iQ",
    "outputId": "8881b2fd-decc-40fd-ae9c-edf8cf1fe452"
   },
   "outputs": [],
   "source": [
    "%pip install stark-qa neo4j python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3s8OR1Ny83V"
   },
   "source": [
    "## Get & Explore STaRK Prime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9q1mODeNL7DU",
    "outputId": "eac7181a-0818-44f0-e3f9-96340affa45b"
   },
   "outputs": [],
   "source": [
    "from stark_qa import load_qa, load_skb\n",
    "\n",
    "dataset_name = 'prime'\n",
    "\n",
    "# Load the retrieval dataset\n",
    "qa_dataset = load_qa(dataset_name)\n",
    "idx_split = qa_dataset.get_idx_split()\n",
    "\n",
    "# Load the semi-structured knowledge base\n",
    "skb = load_skb(dataset_name, download_processed=True, root=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "6_P07iIWUc99",
    "outputId": "2b14600a-8895-4db0-b5ae-d839a3c783f4"
   },
   "outputs": [],
   "source": [
    "qa_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbsSRCGQSO3m"
   },
   "outputs": [],
   "source": [
    "# Get one qa pair, we masked out metadata to avoid answer leaking\n",
    "query, q_id, answer_ids, _ = qa_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8upOq8cSfUS",
    "outputId": "e4153c33-3707-48b5-e82e-fe633d6a0840"
   },
   "outputs": [],
   "source": [
    "query, q_id, answer_ids, _ = qa_dataset[4]\n",
    "print('Query:', query)\n",
    "print('Query ID:', q_id)\n",
    "print('Answer:\\n', '\\n\\n'.join([str(skb[aid].dictionary) for aid in answer_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ot9qm_SnVjGo",
    "outputId": "650e3afe-0e35-4abd-8588-755429d8c821"
   },
   "outputs": [],
   "source": [
    "print(skb.META_DATA)\n",
    "print(skb.NODE_TYPES)\n",
    "print(skb.RELATION_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdrTYwXHZDXj",
    "outputId": "a8422f10-aabd-4c65-f9af-8a8039b24266"
   },
   "outputs": [],
   "source": [
    "skb[answer_ids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alcWipR5zJR-"
   },
   "source": [
    "## Format & Load Nodes\n",
    "\n",
    "1. create a node dataframe\n",
    "2. create function to format node labels based off of type\n",
    "3. helper functions for loading\n",
    "4. load Neo4j credentials from db.env file\n",
    "4. node loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "LrfUmlMRcef2",
    "outputId": "a99a2b71-e80b-4521-9f5c-4aee832a4e76"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# create node_df\n",
    "node_list = []\n",
    "\n",
    "for i in tqdm(range(skb.num_nodes())):\n",
    "  node = skb[i].dictionary\n",
    "  node['nodeId'] = i\n",
    "  node_list.append(skb[i].dictionary)\n",
    "node_df = pd.DataFrame(node_list)\n",
    "\n",
    "# format details\n",
    "node_df.loc[node_df.details.isna(), 'details'] = ''\n",
    "node_df.details = node_df.details.astype(str)\n",
    "\n",
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ch0bd8ybpYg",
    "outputId": "b701bed3-33a2-4ffd-b7a3-aab187dc45fb"
   },
   "outputs": [],
   "source": [
    "# note the node types. We will format these to node labels.\n",
    "skb.node_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sVj0CmSkkgY",
    "outputId": "50787cac-ef10-46e9-a802-95303bd98f66"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# function for formatting\n",
    "def format_node_label(s):\n",
    "  ss = s.replace('/', '_or_').lower().split('_')\n",
    "  return ''.join(t.title() for t in ss)\n",
    "\n",
    "[(k,format_node_label(v)) for k,v in  skb.node_type_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKCXbSGtnP93"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "# helper functions for laoding nodes & rels\n",
    "\n",
    "def _make_map(x):\n",
    "    if type(x) == str:\n",
    "        return x, x\n",
    "    elif type(x) == tuple:\n",
    "        return x\n",
    "    else:\n",
    "        raise Exception(\"Entry must of type string or tuple\")\n",
    "\n",
    "def _make_constraint_query(constraint_type: str, node_label, prop_name) -> str:\n",
    "  const_name = f'{constraint_type.lower()}_{node_label.lower()}_{prop_name.lower()}'\n",
    "  return f'CREATE CONSTRAINT {const_name} IF NOT EXISTS FOR (n:{node_label}) REQUIRE n.{prop_name} IS {constraint_type}'\n",
    "\n",
    "\n",
    "def _make_set_clause(prop_names: ArrayLike, element_name='n', item_name='rec'):\n",
    "    clause_list = []\n",
    "    for prop_name in prop_names:\n",
    "        clause_list.append(f'{element_name}.{prop_name} = {item_name}.{prop_name}')\n",
    "    return 'SET ' + ', '.join(clause_list)\n",
    "\n",
    "\n",
    "def _make_node_merge_query(node_key_name: str, node_label: str, cols: ArrayLike):\n",
    "    template = f'''UNWIND $recs AS rec\\nMERGE(n:{node_label} {{{node_key_name}: rec.{node_key_name}}})'''\n",
    "    prop_names = [x for x in cols if x != node_key_name]\n",
    "    if len(prop_names) > 0:\n",
    "        template = template + '\\n' + _make_set_clause(prop_names)\n",
    "    return template + '\\nRETURN count(n) AS nodeLoadedCount'\n",
    "\n",
    "\n",
    "def _make_rel_merge_query(source_target_labels: Union[Tuple[str, str], str],\n",
    "                          source_node_key: Union[Tuple[str, str], str],\n",
    "                          target_node_key: Union[Tuple[str, str], str],\n",
    "                          rel_type: str,\n",
    "                          cols: ArrayLike,\n",
    "                          rel_key: str = None):\n",
    "    source_target_label_map = _make_map(source_target_labels)\n",
    "    source_node_key_map = _make_map(source_node_key)\n",
    "    target_node_key_map = _make_map(target_node_key)\n",
    "\n",
    "    merge_statement = f'MERGE(s)-[r:{rel_type}]->(t)'\n",
    "    if rel_key is not None:\n",
    "        merge_statement = f'MERGE(s)-[r:{rel_type} {{{rel_key}: rec.{rel_key}}}]->(t)'\n",
    "\n",
    "    template = f'''UNWIND $recs AS rec\n",
    "    MATCH(s:{source_target_label_map[0]} {{{source_node_key_map[0]}: rec.{source_node_key_map[1]}}})\n",
    "    MATCH(t:{source_target_label_map[1]} {{{target_node_key_map[0]}: rec.{target_node_key_map[1]}}})\\n''' + merge_statement\n",
    "    prop_names = [x for x in cols if x not in [rel_key, source_node_key_map[1], target_node_key_map[1]]]\n",
    "    if len(prop_names) > 0:\n",
    "        template = template + '\\n' + _make_set_clause(prop_names, 'r')\n",
    "    return template + '\\nRETURN count(r) AS relLoadedCount'\n",
    "\n",
    "\n",
    "def chunks(xs, n: int = 10_000):\n",
    "    \"\"\"\n",
    "    split an array-like objects into chunks of size n.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    :param n: int\n",
    "        The size of chunk. The last chunk will be the remainder if there is one.\n",
    "    \"\"\"\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]\n",
    "\n",
    "def load_nodes(node_df: pd.DataFrame,\n",
    "               node_key_col: str,\n",
    "               node_label: str,\n",
    "               chunk_size: int = 5_000,\n",
    "               constraint: str = 'UNIQUE',\n",
    "               neo4j_uri: str = 'bolt://localhost:7687',\n",
    "               neo4j_password: str = 'password',\n",
    "               neo4j_username: str = 'neo4j'):\n",
    "    \"\"\"\n",
    "    Load nodes from a dataframe.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    :param node_df: pd.DataFrame\n",
    "        The dataframe containing node data\n",
    "    :param node_key_col: str\n",
    "        The column of the dataframe to use as the MERGE key property\n",
    "    :param node_label: str\n",
    "        The node label to use (only one allowed).\n",
    "    :param chunk_size: int , default 5_000\n",
    "        The chunk size to use when batching rows for loading\n",
    "    :param constraint: str , default \"UNIQUE\"\n",
    "        The constraint to use for the node key. Can be \"UNIQUE\", \"KEY\", or None.\n",
    "        More details at https://neo4j.com/docs/cypher-manual/current/constraints/examples/#constraints-examples-node-uniqueness.\n",
    "        Using 'None' (no node constraint) can result in very poor load performance.\n",
    "    :param neo4j_uri: str , default \"bolt://localhost:7687\"\n",
    "        The uri for the Neo4j database\n",
    "    :param neo4j_password: str , default \"password\"\n",
    "        The password for the Neo4j database\n",
    "    :param neo4j_username: str , default \"neo4j\"\n",
    "        The password for the Neo4j database\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'======  loading {node_label} nodes  ======')\n",
    "\n",
    "    records = node_df.to_dict('records')\n",
    "    total = len(records)\n",
    "    print(f'staged {total:,} records')\n",
    "    with GraphDatabase.driver(neo4j_uri,\n",
    "                              auth=(neo4j_username, neo4j_password)) as driver:\n",
    "      if constraint:\n",
    "        constraint = constraint.upper()\n",
    "        if constraint not in [\"UNIQUE\", \"KEY\"]:\n",
    "          raise ValueError(f'constraint must be one of [\"UNIQUE\", \"KEY\", None] but was {constraint}')\n",
    "        const_query = _make_constraint_query(constraint, node_label, node_key_col)\n",
    "        print(f'\\ncreating constraint:\\n```\\n{const_query}\\n```\\n')\n",
    "        driver.execute_query(const_query)\n",
    "\n",
    "      query = _make_node_merge_query(node_key_col, node_label, node_df.columns.copy())\n",
    "      print(f'\\nusing this Cypher query to load data:\\n```\\n{query}\\n```\\n')\n",
    "      cumulative_count = 0\n",
    "      for recs in chunks(records, chunk_size):\n",
    "          res = driver.execute_query(query, parameters_={'recs': recs})\n",
    "          cumulative_count += res[0][0][0]\n",
    "          print(f'loaded {cumulative_count:,} of {total:,} nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtmxL4Q7oh5H"
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#load neo4j credentials\n",
    "\n",
    "load_dotenv('../db.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv('NEO4J_URI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bs4BLmoEs_Jo",
    "outputId": "40233952-175e-4aa9-83d1-02762f01e7e7"
   },
   "outputs": [],
   "source": [
    "for ind, node_type in skb.node_type_dict.items():\n",
    "  single_node_type_df = (node_df[node_df['type']==node_type]\n",
    "                         .drop(columns=['type']))\n",
    "  node_label = format_node_label(node_type)\n",
    "  load_nodes(single_node_type_df,\n",
    "                   'nodeId',\n",
    "                   node_label,\n",
    "                   neo4j_uri=NEO4J_URI,\n",
    "                   neo4j_password=NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbnUuGt3zPEx"
   },
   "source": [
    "## Format & Load Relationships\n",
    "1. create a relationship dataframe\n",
    "2. create function formatting relationship types based off of typeedge\n",
    "3. relationship loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QakUDBILaoAF",
    "outputId": "63a2b638-9fe3-4b42-a6bb-6964f40c0ac8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "rel_df = pd.DataFrame(\n",
    "    torch.cat([skb.edge_index,\n",
    "               skb.edge_types.reshape(1, skb.edge_types.size()[0])],\n",
    "              dim=0).t(),\n",
    "     columns = ['src', 'tgt', 'typeId'])\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RTdRlrsdw4V",
    "outputId": "2eec7879-859b-4c32-f455-7a7973f77bff"
   },
   "outputs": [],
   "source": [
    "rel_types = skb.edge_type_dict\n",
    "rel_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaJlIM_MeEQ1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_rel_type(s):\n",
    "  return re.sub('[^0-9A-Z]+', '_', s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETeg-wh7emBQ",
    "outputId": "0a9f49f0-6be4-49d7-bc5b-7c489d4eba1b"
   },
   "outputs": [],
   "source": [
    "[(k,format_rel_type(v)) for k,v in  skb.edge_type_dict.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ma2IobWJ_O6F"
   },
   "outputs": [],
   "source": [
    "# creating unifying node label for relationship load\n",
    "\n",
    "with GraphDatabase.driver(NEO4J_URI,\n",
    "                              auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "  driver.execute_query('MATCH(n) SET n:_Entity_')\n",
    "  driver.execute_query('CREATE CONSTRAINT unique__entity__nodeid IF NOT EXISTS FOR (n:_Entity_) REQUIRE n.nodeId IS UNIQUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0-kj81Y6hbt"
   },
   "outputs": [],
   "source": [
    "def load_rels(rel_df: pd.DataFrame,\n",
    "              source_target_labels: Union[Tuple[str, str], str],\n",
    "              source_node_key: Union[Tuple[str, str], str],\n",
    "              target_node_key: Union[Tuple[str, str], str],\n",
    "              rel_type: str,\n",
    "              rel_key: str = None,\n",
    "              chunk_size: int = 10_000,\n",
    "              neo4j_uri: str = 'bolt://localhost:7687',\n",
    "              neo4j_password: str = 'password',\n",
    "              neo4j_username: str = 'neo4j'):\n",
    "    \"\"\"\n",
    "    Load relationships from a dataframe.\n",
    "\n",
    "    Parameters\n",
    "    -------\n",
    "    :param rel_df: pd.DataFrame\n",
    "        The dataframe containing relationship data\n",
    "    :param source_target_labels: Union[Tuple[str, str], str]\n",
    "        The source and target node labels to use.\n",
    "        Can pass a single string if source and target nodes have the same labels,\n",
    "        otherwise a tuple of the form (source_node_label, target_node_label)\n",
    "    :param source_node_key: Union[Tuple[str, str], str]\n",
    "        The column of the dataframe to use as the source node MERGE key property.\n",
    "        Can optionally pass a tuple of the form (source_node_key_name, df_column_name) to map as appropriate if the\n",
    "        column name is different\n",
    "    :param target_node_key: Union[Tuple[str, str], str]\n",
    "        The column of the dataframe to use as the target node MERGE key property.\n",
    "        Can optionally pass a tuple of the form (target_node_key_name, df_column_name) to map as appropriate if the\n",
    "        column name is different\n",
    "    :param rel_type: str\n",
    "        The relationship type to use (only one allowed).\n",
    "    :param rel_key: str\n",
    "        A key to distinguish unique parallel relationships.\n",
    "        The default behavior of this function is to assume only one instance of a relationship type between two nodes.\n",
    "        A duplicate insert will have the behavior of overriding the existing relationship.\n",
    "        If this behavior is undesirable, and you want to allow multiple instances of the same relationship type between\n",
    "        two nodes (a.k.a parallel relationships), provide this key to use for merging relationships uniquely\n",
    "    :param chunk_size: int , default 5_000\n",
    "        The chunk size to use when batching rows for loading\n",
    "    :param neo4j_uri: str , default \"bolt://localhost:7687\"\n",
    "        The uri for the Neo4j database\n",
    "    :param neo4j_password: str , default \"password\"\n",
    "        The password for the Neo4j database\n",
    "    :param neo4j_username: str , default \"neo4j\"\n",
    "        The password for the Neo4j database\n",
    "    \"\"\"\n",
    "    records = rel_df.to_dict('records')\n",
    "    print(f'======  loading {rel_type} relationships  ======')\n",
    "    total = len(records)\n",
    "    print(f'staged {total:,} records')\n",
    "    with GraphDatabase.driver(neo4j_uri,\n",
    "                              auth=(neo4j_username, neo4j_password)) as driver:\n",
    "      query = _make_rel_merge_query(source_target_labels, source_node_key,\n",
    "                                  target_node_key, rel_type, rel_df.columns.copy(), rel_key)\n",
    "      print(f'\\nusing this cypher query to load data:\\n```\\n{query}\\n```\\n')\n",
    "      cumulative_count = 0\n",
    "      for recs in chunks(records, chunk_size):\n",
    "          res = driver.execute_query(query, parameters_={'recs': recs})\n",
    "          cumulative_count += res[0][0][0]\n",
    "          print(f'loaded {cumulative_count:,} of {total:,} relationships')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maosp4AM2klk",
    "outputId": "dfbb86a5-df03-4bed-d8cc-20e875f84949"
   },
   "outputs": [],
   "source": [
    "for ind, edge_type in skb.edge_type_dict.items():\n",
    "  single_rel_type_df = (rel_df[rel_df['typeId']==ind]\n",
    "                         .drop(columns=['typeId']))\n",
    "  rel_type = format_rel_type(edge_type)\n",
    "  load_rels(single_rel_type_df,\n",
    "              source_target_labels='_Entity_',\n",
    "              source_node_key=('nodeId', 'src'),\n",
    "              target_node_key=('nodeId', 'tgt'),\n",
    "              rel_type=rel_type ,\n",
    "              neo4j_uri=NEO4J_URI,\n",
    "              neo4j_password=NEO4J_PASSWORD)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE7G8eCgmT2N"
   },
   "source": [
    "## Get & Load Embeddings\n",
    "1. download pre-computed text-embedding-ada-002 embeddings\n",
    "2. format embeddings\n",
    "3. load embeddings\n",
    "4. create vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDuMxfQRIy4C",
    "outputId": "0ae70237-7253-4bff-8c22-b9c9a24f1f80"
   },
   "outputs": [],
   "source": [
    "# Load pre-generated openai text-embedding-ada-002 embeddings\n",
    "# Get emb_download.py from https://github.com/snap-stanford/stark. see Readme for other ways to generate embeddings\n",
    "! python emb_download.py --dataset prime --emb_dir emb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAqwFV9cJ7Sa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "emb = torch.load('emb/prime/text-embedding-ada-002/doc/candidate_emb_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6ws2QfqKP1F",
    "outputId": "9c5ec917-eb80-44c2-ac1b-6971c8283b8f"
   },
   "outputs": [],
   "source": [
    "emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fuh-gu-SKgEB",
    "outputId": "0fafa9f7-669e-445f-9dec-99b797d3a5e5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# format embedding records\n",
    "emb_records = []\n",
    "for k,v in tqdm(emb.items()):\n",
    "  emb_records.append({\"nodeId\":k ,\"textEmbedding\": v.squeeze().tolist()})\n",
    "emb_records[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_ev2N5RMiX-",
    "outputId": "6a4cd635-1cfd-4345-c088-437d0a579a59"
   },
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "\n",
    "print(f'======  loading text embeddings ======')\n",
    "\n",
    "total = len(emb_records)\n",
    "print(f'staged {total:,} records')\n",
    "with GraphDatabase.driver(NEO4J_URI,\n",
    "                          auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "\n",
    "  query = \"\"\"\n",
    "  UNWIND $recs AS rec\n",
    "  MATCH(n:_Entity_ {nodeId: rec.nodeId})\n",
    "  CALL db.create.setNodeVectorProperty(n, \"textEmbedding\", rec.textEmbedding)\n",
    "  RETURN count(n) AS embeddingLoadedCount\n",
    "  \"\"\"\n",
    "  print(f'\\nusing this Cypher query to load data:\\n```\\n{query}\\n```\\n')\n",
    "  cumulative_count = 0\n",
    "  for recs in chunks(emb_records, 1_000):\n",
    "      res = driver.execute_query(query, parameters_={'recs': recs})\n",
    "      cumulative_count += res[0][0][0]\n",
    "      print(f'loaded {cumulative_count:,} of {total:,} embeddings')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WRCoNTOPM5w"
   },
   "outputs": [],
   "source": [
    "# create vector index\n",
    "\n",
    "with GraphDatabase.driver(NEO4J_URI,\n",
    "                          auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "  driver.execute_query('''\n",
    "  CREATE VECTOR INDEX textembeddings IF NOT EXISTS FOR (n:_Entity_) ON (n.textEmbedding)\n",
    "  OPTIONS {indexConfig: {\n",
    "  `vector.dimensions`: toInteger($dimension),\n",
    "  `vector.similarity_function`: 'cosine'\n",
    "  }}''', parameters_={'dimension': len(emb_records[0]['textEmbedding'])})\n",
    "  driver.execute_query('CALL db.awaitIndex(\"textembeddings\", 300)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate relationship type embedding for all 18 reltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "reltype_emb_path = 'emb/prime/text-embedding-ada-002/doc/reltype_emb_dict.pt'\n",
    "if not os.path.exists(reltype_emb_path):\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    reltype_emb = {format_rel_type(v): embedding_model.embed_query(v) for k,v in  skb.edge_type_dict.items()}\n",
    "    import torch\n",
    "    torch.save(reltype_emb, 'emb/prime/text-embedding-ada-002/doc/reltype_emb_dict.pt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gretriever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
